{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import seaborn as sb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.feature_extraction as fe\n",
    "import sklearn.preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, GridSearchCV\n",
    "import sklearn.neighbors as nhb\n",
    "import sklearn.ensemble as es\n",
    "import sklearn.tree as tree\n",
    "from sklearn import svm\n",
    "import sklearn.naive_bayes as nb\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.metrics import classification_report, fbeta_score, make_scorer, log_loss, accuracy_score, roc_curve, brier_score_loss, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "import sklearn.calibration as cl\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pandas.read_csv('data/account_histroy_data.csv')\n",
    "test = pandas.read_csv('data/existing_account.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>IsMale</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>763</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>153983.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>563</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>143680.47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63531.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>678</td>\n",
       "      <td>Spain</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>124483.53</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>126253.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>644</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>86006.30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73922.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>682</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>111094.05</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64679.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  IsMale  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          763    France       0   23       2       0.00              2   \n",
       "1          563     Spain       0   36       4  143680.47              2   \n",
       "2          678     Spain       1   38       3  124483.53              1   \n",
       "3          644     Spain       0   31       5   86006.30              1   \n",
       "4          682   Germany       0   43       7  111094.05              2   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0          1               0        153983.99  \n",
       "1          1               1         63531.19  \n",
       "2          1               0        126253.31  \n",
       "3          1               1         73922.95  \n",
       "4          1               1         64679.30  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(labels = ['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "train = train.replace({'Gender': {'Female': 0, 'Male': 1}})\n",
    "train = train.rename(columns={'Gender': 'IsMale'})\n",
    "test = test.drop(labels = ['CustomerId', 'Surname'], axis=1)\n",
    "test = test.replace({'Gender': {'Female': 0, 'Male': 1}})\n",
    "test = test.rename(columns={'Gender': 'IsMale'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd3fc72bcc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matplotlib.style.use('ggplot')\n",
    "train['IsMale'].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial analysis\n",
    "\n",
    "* `RowNumber`, `CustomerID` and `Surname` can be dropped \n",
    "* `CreditScore` whilst numerical should be treated more like a ordinal variable. Nice and normal distribution. No missing values\n",
    "* `Age` is nicely behaved: no missing values, nice and finite, nice and normally distributed\n",
    "* `Tenure` is similarly nicely behaved: no missing values, finitely bounded and practically uniformally distributed. What does this variable represent? Age of account?\n",
    "* `Balance` is a bit more interesting: there's a large spike at ~<= 30k and then a normally distributed group centered at just over 100k. This suggests 2 separate populations. No na values\n",
    "* `NumOfProducts` is uninteresting: no missing values, all integers in [1,4]. All same order of magnitude\n",
    "* `HasCrCard` binary variable indicating credit card ownership. No missing values. Distribution of both classes is same order of magnitude, positive value (`1`) outweighs `0` value by about 4k occurences.\n",
    "* `IsActiveMember` binary variable. Practically class sizes. No missing values.\n",
    "* `EstimatedSalary` nicely behaved: uniform distribution with no missing values and all values in the same order of magnitude.\n",
    "* `Exited` Target variable. 1 indicates customer left, inbalanced classes with most cases in the \"stayed\" category.\n",
    "\n",
    "# Potential process\n",
    "\n",
    "* Given we don't have to worry about missing values, send the data straight to an `sklearn DictVectoriser` (as we want to track column names) followed by `OneHotEncoder` to handle binary variables that \n",
    "* This will automatically handle binarising our categorical variables.\n",
    "* Most variables were normally or uniformally distributed, so standard scaling should be sufficient, but test with robust scaling as well.\n",
    "* We've got enough data points that we can comfortable affort to slice off a portion of the dataset as a validation set. This can be done post scaling, pre test-train split. This will help prevent overfitting.\n",
    "* The class imbalance isn't too bad (they're both on the same order of magnitude), but it would be worth testing over/under/synthetic sampling approaches anyways.\n",
    "* We're treating this as a classification exercise, so let's run it across Naive Bayes, some forests of trees, gradient boosting, SVM's. As a baseline/sanity check let's run super basic logistic and single-tree models as well. ~~Bigger~~ Fancier isn't always better.\n",
    "* Model stacking and voting classifiers (soft and hard) are also worth investigating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>IsMale</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [CreditScore, Geography, IsMale, Age, Tenure, Balance, NumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary, Exited]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['EstimatedSalary'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fdad03320f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = train[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited']].corr()\n",
    "camp = sb.diverging_palette(220, 10, as_cmap=True)\n",
    "sb.heatmap(corr, cmap=camp, square=True, linewidths=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Matrix\n",
    "While it appears pretty uniform at first glance, there's some interesting stuff lurking here: whilst most of the variables exhibit near 0 correlation, there's some positive correlation between `age` and `exited` and some (relatively) strong negative correlation between `NumOfProducts` and `Balance`. There's also a weak negative correlation between `IsActiveMember` and `Exited`; possibly too weak to be useful, but worth keeping in mind.\n",
    "\n",
    "# Feature Engineering\n",
    "Add some features that we think might add some extra information/structure to the dataset - models and feature selection will drop them back out if they turn out to not be useful.\n",
    "* Balance / NumOfProducts?\n",
    "* EstimatedSalary / NumOfProducts\n",
    "* NumOfProducts / Tenure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.assign(\n",
    "    BalanceByProducts=(train['Balance'] / train['NumOfProducts']), \n",
    "    SalaryByProducts=(train['EstimatedSalary'] / train['NumOfProducts']))\n",
    "test = test.assign(\n",
    "    BalanceByProducts=(test['Balance'] / test['NumOfProducts']), \n",
    "    SalaryByProducts=(test['EstimatedSalary'] / test['NumOfProducts']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's slice off a validation set now so we can completely isolate it from the train and test data.\n",
    "validation = train[['CreditScore', 'Geography', 'IsMale', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember',\n",
    "                    'EstimatedSalary','BalanceByProducts','SalaryByProducts', 'Exited']].sample(frac=0.1)\n",
    "train2 = train[~train.index.isin(validation.index)]# Drop the validation values from the primary train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>IsMale</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>BalanceByProducts</th>\n",
       "      <th>SalaryByProducts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101348.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>83807.860000</td>\n",
       "      <td>112542.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>53220.266667</td>\n",
       "      <td>37977.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46913.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>125510.820000</td>\n",
       "      <td>79084.100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  IsMale  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France       0   42       2       0.00              1   \n",
       "1          608     Spain       0   41       1   83807.86              1   \n",
       "2          502    France       0   42       8  159660.80              3   \n",
       "3          699    France       0   39       1       0.00              2   \n",
       "4          850     Spain       0   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  BalanceByProducts  \\\n",
       "0          1               1        101348.88       1           0.000000   \n",
       "1          0               1        112542.58       0       83807.860000   \n",
       "2          1               0        113931.57       1       53220.266667   \n",
       "3          0               0         93826.63       0           0.000000   \n",
       "4          1               1         79084.10       0      125510.820000   \n",
       "\n",
       "   SalaryByProducts  \n",
       "0        101348.880  \n",
       "1        112542.580  \n",
       "2         37977.190  \n",
       "3         46913.315  \n",
       "4         79084.100  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_target(data):\n",
    "    cols = data.columns\n",
    "    target = data['Exited']\n",
    "    rem = data[cols.drop('Exited')]\n",
    "    return rem, target\n",
    "\n",
    "def re_order_unbind(data): \n",
    "    re_ordering = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary', 'BalanceByProducts', 'SalaryByProducts',\n",
    "                   'IsMale', 'HasCrCard', 'IsActiveMember', 'Geography_France', 'Geography_Germany', 'Geography_Spain',]\n",
    "    num_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary','BalanceByProducts', 'SalaryByProducts']\n",
    "    cat_cols = ['IsMale', 'HasCrCard', 'IsActiveMember', 'Geography_France', 'Geography_Germany', 'Geography_Spain']\n",
    "    data = data[re_ordering]\n",
    "    numerical = data[num_cols]\n",
    "    categorical = data[cat_cols]\n",
    "    return numerical, categorical\n",
    "\n",
    "def re_order_unbind_2(data):  # Should have just parametised the first function, oh well\n",
    "    re_ordering = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary', 'BalanceByProducts', 'SalaryByProducts',\n",
    "                   'IsMale', 'HasCrCard', 'IsActiveMember', 'Geography_France', 'Geography_Germany', 'Geography_Spain', 'meta_svm', 'meta_gb']\n",
    "    num_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary','BalanceByProducts', 'SalaryByProducts']\n",
    "    cat_cols = ['IsMale', 'HasCrCard', 'IsActiveMember', 'Geography_France', 'Geography_Germany', 'Geography_Spain', 'meta_svm', 'meta_gb']\n",
    "    data = data[re_ordering]\n",
    "    numerical = data[num_cols]\n",
    "    categorical = data[cat_cols]\n",
    "    return numerical, categorical\n",
    "\n",
    "def scale_rebind(num, cat):\n",
    "    scalefn = pp.StandardScaler()\n",
    "    scaled = scalefn.fit_transform(num)\n",
    "    return np.concatenate([scaled, cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lots of algorithms expect (and perform better) when data is in the same scale. However, it doesn't much sense to scale categorical variables, so we re-order the dataset for ease of interpretation then separate it\n",
    "# into numerical and categorical sections, scale the numerical data and then rejoin everything back into the one dataset. Turning it into a function means we have a nice, single place to change our scaling type\n",
    "# later if we want to test other types.\n",
    "\n",
    "X,Y = sep_target(train2)\n",
    "tempX = pandas.get_dummies(X)  # Splits categorical/text columns containing n categories into n binary variables\n",
    "Xn, Xc = re_order_unbind(tempX)\n",
    "Xs = scale_rebind(Xn, Xc)\n",
    "\n",
    "valX, valY = sep_target(validation)\n",
    "temp_valX = pandas.get_dummies(valX)\n",
    "valXn, valXc = re_order_unbind(temp_valX)\n",
    "valXs = scale_rebind(valXn, valXc)\n",
    "\n",
    "test2 = pandas.get_dummies(test)\n",
    "testn, testc = re_order_unbind(test2)\n",
    "tests = scale_rebind(testn, testc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thoughts on ML/fitting process\n",
    "\n",
    "We are trying to predict whether a user will leave/stop being a customer. We have a large choice of metrics with which to evaluate estimator performance. Measuring model confidence via probabilities would be ideal as it will let us generate the `log-loss` metric which means we can optimise for an estimator that is not \"confidently wrong\" which would result in lost clients. Outputting probabilities is also useful because it would give the sales/retention/etc team the ability to prioritise certain customers based on how likely they are to churn. `F1` or `Fbeta` score would probably be the next best metric to evaluate with. Weighting for `Fbeta` could go either way. On one hand we don't want to raise false-positives on clients that weren't going to churn because this wastes sales' effort (but has no negative effect on the customer), but weighting too heavily for precision could lead to potential churn-customers being lost in order for the model to preserve the accuracy of the ones it is confident in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'svm': svm.SVC(),\n",
    "    'svm_poly': svm.SVC(),\n",
    "    'knn': nhb.KNeighborsClassifier(),\n",
    "    'naive_bayes': nb.GaussianNB(),\n",
    "#     'decision_tree': tree.DecisionTreeClassifier(),\n",
    "    'random_forest': es.RandomForestClassifier(),\n",
    "    'adaBoost': es.AdaBoostClassifier(),\n",
    "    'Gradient_Boosting': es.GradientBoostingClassifier(),\n",
    "    'Logistic_Regression': lm.LogisticRegression()\n",
    "    #'Voting classifier'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'C': 0.5, 'class_weight': 'balanced', 'coef0': 0.4, 'degree': 3, 'gamma': 0.3, 'kernel': 'poly', 'probability': True, 'random_state': 74}\n",
    "svm_params = {'C': [1, 0.5, 0.1], 'kernel': ['linear', 'rbf',], 'gamma': ['auto', 0.3], \n",
    "             'probability': [True], 'class_weight': ['balanced', None], 'random_state': [74]}\n",
    "svm_poly_params = {'C': [0.5, 0.8, 0.25], 'kernel': ['poly'], 'degree': [2,3,5], 'gamma': ['auto', 0.1, 0.3], 'coef0': [0, 0.4, 0.6],\n",
    "                'probability': [True], 'class_weight': ['balanced', None], 'random_state': [74]},\n",
    "knn_params = {'n_neighbors': [3, 5, 9, 10, 15], 'weights': ['uniform', 'distance'], 'algorithm': ['kd_tree']}\n",
    "nb_params = None\n",
    "tree_params = None\n",
    "forest_params = {'n_estimators': [50, 80, 150, 200, 250], 'max_features': ['auto', None, 0.5,0.8], 'min_samples_split': [0.3, 0.5, 0.8],\n",
    "                'bootstrap': [True, False], 'n_jobs': [-1], 'random_state': [74], 'class_weight': ['balanced', None, 'balanced_subsample'], 'warm_start': [False]}\n",
    "ada_params = {'n_estimators': [30, 40, 50, 80, 100, 150], 'learning_rate': [0.1, 0.2, 0.3, 0.35, 0.25], 'random_state': [74]},\n",
    "gb_params = {'learning_rate': [0.1, 0.05], 'n_estimators': [100, 200, 300, 400, 500, 600], 'max_depth': [3, 6, 10], 'min_samples_split': [0.5, 0.3, 0.75],\n",
    "            'min_samples_leaf': [1,3, 0.5, 0.2], 'subsample': [0.5, 1], 'max_features': [None, 'auto'], 'random_state': [74]}\n",
    "logistic_params = {'C': [1, 0.75, 0.6, 0.4], 'class_weight': ['balanced', None], 'random_state': [74], 'max_iter': [300], 'warm_start': [True, False]}\n",
    "voting_params = None\n",
    "params = {#'svm': svm_params,\n",
    "          'svm_poly': svm_poly_params,\n",
    "          'knn': knn_params,\n",
    "#           'decision TREE': tree_params,\n",
    "          #'random_forest': forest_params,\n",
    "          'adaBoost': ada_params,\n",
    "          'Gradient_Boosting': gb_params,\n",
    "          'Logistic_Regression': logistic_params}\n",
    "#           'Voting classifier': voting_params}  # Leave this one out until we've got some good models to vote with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model: svm_poly\n",
      "{'C': 0.25, 'class_weight': 'balanced', 'coef0': 0.4, 'degree': 3, 'gamma': 0.3, 'kernel': 'poly', 'probability': True, 'random_state': 74}\n",
      "5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.80      0.85       758\n",
      "          1       0.49      0.68      0.57       212\n",
      "\n",
      "avg / total       0.81      0.78      0.79       970\n",
      "\n",
      "\n",
      "\n",
      "Testing model: knn\n",
      "{'algorithm': 'kd_tree', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.92      0.88       758\n",
      "          1       0.59      0.43      0.50       212\n",
      "\n",
      "avg / total       0.79      0.81      0.80       970\n",
      "\n",
      "\n",
      "\n",
      "Testing model: adaBoost\n",
      "{'learning_rate': 0.35, 'n_estimators': 150, 'random_state': 74}\n",
      "5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.96      0.90       758\n",
      "          1       0.73      0.39      0.51       212\n",
      "\n",
      "avg / total       0.82      0.84      0.82       970\n",
      "\n",
      "\n",
      "\n",
      "Testing model: Gradient_Boosting\n",
      "{'learning_rate': 0.05, 'max_depth': 6, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 0.3, 'n_estimators': 600, 'random_state': 74, 'subsample': 1}\n",
      "5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.96      0.91       758\n",
      "          1       0.74      0.43      0.55       212\n",
      "\n",
      "avg / total       0.83      0.84      0.83       970\n",
      "\n",
      "\n",
      "\n",
      "Testing model: Logistic_Regression\n",
      "{'C': 0.4, 'class_weight': 'balanced', 'max_iter': 300, 'random_state': 74, 'warm_start': True}\n",
      "5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.73      0.80       758\n",
      "          1       0.40      0.65      0.50       212\n",
      "\n",
      "avg / total       0.78      0.71      0.73       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We're going to build the models to optimise for recall first, then model stack with the best one(s) and then build a 2nd generation of models optimising for precision/log-loss.\n",
    "for model, parameters in params.items():\n",
    "    print()\n",
    "    print()\n",
    "    print(f'Testing model: {model}')\n",
    "    clf = GridSearchCV(estimator=models[model],\n",
    "                       param_grid=parameters,\n",
    "                       cv=5,\n",
    "                       scoring='recall',\n",
    "                       n_jobs=-1,\n",
    "                      refit='recall')\n",
    "    clf.fit(Xs, Y)\n",
    "    print(clf.best_params_)\n",
    "    print(clf.n_splits_)\n",
    "    est = clf.best_estimator_\n",
    "    y_pred = est.predict(valXs)\n",
    "    print(classification_report(valY, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Results:\n",
    "* Plain SVM's performed average at best, with middling precision but good recall: `0.49` and `0.72` respectively and `0.58` for the f1 score.\n",
    "* Polynomial SVM's performed better with improvements to precision, recall and f1 score: `0.5`, `0.74` and `0.6` respectively.\n",
    "Optimising precision and recall is a tradeoff, but for our case, because we don't want to risk losing customers, we want to bias slightly towards recall.\n",
    "* Plain random forests and adaBoost haven't been too suitable for our use-case: they both perform exceedingly well with regards to precision - scoring `0.81` and `0.94` respectively but very poorly when it comes to recall with both models scoring `<= 0.1` for the target value (left). This isn't ideal as it means that whilst their predictions for customers leaving are accurate (they're generating very few false positives), they're essentially underestimating/underpredicting the number of customers who would leave. That is, in production, they would not flag a large percentage of customers who are about to leave.\n",
    "* There is an upside, we can still make use of the high precision of these models by using model-stacking. This is where we'll use a model (adaBoost and svm_poly in this case) to generate predictions for all samples in the greater training and validation set (`Xs` and `valXs`) and these add a column in each dataset. We'll then train another model using this new dataset, this allows us to guide/help successive models with extra information.\n",
    "\n",
    "# Best models so far:\n",
    "Polynomial SVM (for best recall)\n",
    "```\n",
    "{'C': 0.25, 'class_weight': 'balanced', 'coef0': 0.4, 'degree': 3, 'gamma': 0.3, 'kernel': 'poly', 'probability': True, 'random_state': 74}\n",
    "5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          0       0.90      0.80      0.85       758\n",
    "          1       0.49      0.68      0.57       212\n",
    "\n",
    "avg / total       0.81      0.78      0.79       970``` \n",
    "\n",
    "\n",
    "Gradient Boosting Trees  (for best precision)\n",
    "```\n",
    "{'learning_rate': 0.05, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 0.3, 'n_estimators': 200, 'random_state': 74, 'subsample': 1}\n",
    "5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          0       0.87      0.95      0.91       767\n",
    "          1       0.72      0.45      0.55       203\n",
    "\n",
    "avg / total       0.84      0.85      0.83       970```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "#Let's roll with the polynomial SVM for now, as that seems to have the best balance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison\n",
    "\n",
    "We've got a couple of models that perform quite well on the validation set, to compare them further we'll evaluate their scores in a couple of other metrics, notably log-loss, ROC area-under-curve and overall accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check log-loss and ROC-AUC stats for these, then see if their probability-calibrated versions yield any improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_scoring(validation, y_true, model):\n",
    "    y_predicted = model.predict(validation)\n",
    "    probs_predicted = model.predict_proba(validation)\n",
    "    log_loss_res = log_loss(y_true=y_true, y_pred=probs_predicted[:, 1])\n",
    "    roc_auc_res = roc_curve(y_true=y_true, y_score=probs_predicted[:, 1])\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_predicted)\n",
    "    # Regenerate precision and recall just so we can compare everything in one place\n",
    "    prec = precision_score(y_true=y_true, y_pred=y_predicted)\n",
    "    rec = recall_score(y_true=y_true, y_pred=y_predicted)\n",
    "    cnfsn_matrix = confusion_matrix(y_true=y_true, y_pred=y_predicted)\n",
    "    tn, fp, fn, tp = cnfsn_matrix.ravel()\n",
    "#     Informedness = Sensitivity + Specificity − 1\n",
    "    informedness = rec + (tp / (fp + tn)) - 1\n",
    "#     Markedness = PPV + NPV − 1\n",
    "    markedness = prec + (tn / (tn + fn)) - 1\n",
    "    print(f'Log-loss: {log_loss_res}')\n",
    "#     print(f'ROC-AUC: {roc_auc_res}') Exclude this for now, as a plot of the ROC curve is probably more useful\n",
    "#     Add ROC curve plots\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {prec}')\n",
    "    print(f'Recall: {rec}')\n",
    "#     Add (normalised) confusion matrix plots here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,13.5095,'Predicted label')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "temp = clf1.predict(valXs)\n",
    "cfnm = confusion_matrix(valY, temp)\n",
    "cfnm = cfnm/cfnm.sum(axis=1)[:, np.newaxis]\n",
    "plt.imshow(cfnm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "plt.xticks([0.5], (0,1), rotation=45)\n",
    "plt.yticks([0.5], (0,1), rotation=45)\n",
    "thold = cfnm.max() / 2.\n",
    "for i, j in itertools.product(range(cfnm.shape[0]), range(cfnm.shape[1])):\n",
    "    plt.text(j, i, format(cfnm[i, j], '.2f'), horizontalalignment='center', color='white' if cfnm[i,j] > thold else 'black')\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      "Log-loss: 0.3365321637546616\n",
      "Accuracy: 0.8134020618556701\n",
      "Precision: 0.5107913669064749\n",
      "Recall: 0.7593582887700535\n",
      "\n",
      "Gradient Boosting:\n",
      "Log-loss: 0.31977003454912356\n",
      "Accuracy: 0.8649484536082475\n",
      "Precision: 0.7058823529411765\n",
      "Recall: 0.5133689839572193\n"
     ]
    }
   ],
   "source": [
    "svc = {'C': 0.25, 'class_weight': 'balanced', 'coef0': 0.4, 'degree': 3, 'gamma': 0.3, 'kernel': 'poly', 'probability': True, 'random_state': 74}\n",
    "gbc = {'learning_rate': 0.05, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 0.3, 'n_estimators': 200, 'random_state': 74, 'subsample': 1}\n",
    "clf1 = svm.SVC().set_params(**svc).fit(Xs, Y)\n",
    "clf2 = es.GradientBoostingClassifier().set_params(**gbc).fit(Xs, Y)\n",
    "print('SVM:')\n",
    "basic_scoring(valXs, valY, clf1)\n",
    "print()\n",
    "print('Gradient Boosting:')\n",
    "basic_scoring(valXs, valY, clf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models exhibit some reasonably nice results. The SVM has been optimised for recall, and the gradient boost has been optimised for accuracy.\n",
    "We'll run variable importance using the gradient boosting model and see if there's any variables we can drop. We'll then model stack using both models (i.e. add both models predictions to the training and validation sets) and then re-run with a model trained for accuracy or log-loss. Why model stack? Why isn't the gradient boosting/SVM model good enough on its own? In my opinion, the GB isn't good enough by itself because it misses a non-trivial portion of the positive cases. In a production environment, this would mean that while it's predictions for customers that will exit will be correct, there is a significant number of customers that it would miss. \n",
    "This is partially mitigated by low log-loss, which can be affected by outputting the probability of exit, rather than a yes/no for exit and then ranking customers by this probability because the models low log-loss translates into low confidence on incorrect cases which means that they will be near a decision boundary implying a moderate probability. This means Sales/retention/etc has more information on which customers to target rather than a bright-line yes/no. With these constraints/approaches in place, we could arguably stop here and just use the GB model with the mitigations in place, but I think we should go further.\n",
    "\n",
    "The models have different strengths, so we're going to use both to build \"meta\" columns for our 2nd generation model.\n",
    "\n",
    "* log-loss, which measures how \"confident\" a model is about incorrect results is quite an important metric: ideally, when the model incorrectly classifies a customer as \"staying\", we want it to do so in such a way that has these cases near the decision boundary (i.e. the probability of that case being \"stay\" is low\", but not low enough to be cleanly classified as \"exiting\"). This means that when we rank the customers by probability of leaving, these customers will be near the middle, giving us more information to make a decision about who to follow up with beyond \"will exit/won't exit\".\n",
    "    * Both models score well in this metric: `0.359` and `0.367` for the SVM and Gradient Boosting respectively. A lower score is better, with the metric having a lower bound at 0, representing a perfect score.\n",
    "* Accuracy measures how many correct classifications were made across both classes. It is best viewed in combination with precision and recall to get a full picture of how well a model does what you wish (for example, you want an accurate model, but you . Higher scores are better, with the metric `[0,1]` bounded.\n",
    "    * Both models perform well, with the GB having a small lead - `0.798` and `0.841` for the SVM and GB respectively\n",
    "* Precision and Recall are a pair of metrics that measure \"quality\" and \"quantity\" respectively. Precision measures the fraction of cases marked as \"positive\" that were actually \"positive\". Recall measures the fraction of \"positive\" cases that were marked as \"positive\" by the classifier. Optimising a given classifier is a balance between these 2 metrics, as recall can be improved by essentially marking more cases as positive (which drives down precision) and precision can be boosted by essentially tightening decision boundaries to return fewer results but only correct ones (which would drive down recall, because you would be excluding valid \"positive\" cases). Once again, both metrics are `[0,1]` bounded and higher is better.\n",
    "    * Precision for both classifiers is very good: `0.510` and `0.685` for the SVM and the Gradient Boosted models respectively.\n",
    "    \n",
    "# Conclusions\n",
    "    \n",
    "* Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.predict(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss: 8.296576935205211\n",
      "Log-loss: 5.376689503838744\n",
      "No calibration SVC: 0.11990238439982598\n",
      "Sigmoid calibration: 0.11545138732209186\n",
      "Sigmoid calibration: 0.12018441325708971\n",
      "No calibration Gradient Boosting: 0.11048031215674682\n",
      "Sigmoid calibration: 0.11118911776845422\n",
      "Sigmoid calibration: 0.11178568295734097\n"
     ]
    }
   ],
   "source": [
    "# Maybe table the probability calibration for now, as we really don't care _that_ much for these models.\n",
    "\n",
    "svc = {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.3, 'kernel': 'rbf', 'probability': True, 'random_state': 74}\n",
    "gbc = {'learning_rate': 0.1, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 0.3, 'n_estimators': 600, 'random_state': 74, 'subsample': 1}\n",
    "clf1 = svm.SVC().set_params(**svc).fit(Xs, Y)\n",
    "clf2 = es.GradientBoostingClassifier().set_params(**gbc).fit(Xs, Y)\n",
    "basic_scoring(valXs, valY, clf1)\n",
    "basic_scoring(valXs, valY, clf2)\n",
    "\n",
    "svm_pc1 = cl.CalibratedClassifierCV(base_estimator=svm.SVC(), cv=5, method='sigmoid')\n",
    "svm_pc2 = cl.CalibratedClassifierCV(base_estimator=svm.SVC().set_params(**svc), cv=5, method='sigmoid').fit(Xs, Y)\n",
    "svm_pc3 = cl.CalibratedClassifierCV(base_estimator=clf1, cv='prefit', method='sigmoid')\n",
    "gb_pc1 = cl.CalibratedClassifierCV(base_estimator=es.GradientBoostingClassifier(), cv=5, method='sigmoid').fit(Xs, Y)\n",
    "gb_pc2 = cl.CalibratedClassifierCV(base_estimator=es.GradientBoostingClassifier().set_params(**gbc), cv=5, method='sigmoid').fit(Xs, Y)\n",
    "\n",
    "uncalibratedSVM = clf1.predict_proba(valXs)[:,1]\n",
    "uncalibratedGB = clf2.predict_proba(valXs)[:,1]\n",
    "calibrated_svm1 = svm_pc1.fit(Xs, Y).predict_proba(valXs)[:, 1]\n",
    "calibrated_svm2 = svm_pc2.fit(Xs, Y).predict_proba(valXs)[:, 1]\n",
    "calibrated_gb1 = gb_pc1.fit(Xs, Y).predict_proba(valXs)[:,1]\n",
    "calibrated_gb2 = gb_pc2.fit(Xs, Y).predict_proba(valXs)[:,1]\n",
    "\n",
    "print(f'No calibration SVC: {brier_score_loss(valY, uncalibratedSVM)}')\n",
    "print(f'Sigmoid calibration: {brier_score_loss(valY, calibrated_svm1)}')\n",
    "print(f'Sigmoid calibration: {brier_score_loss(valY, calibrated_svm2)}')\n",
    "print(f'No calibration Gradient Boosting: {brier_score_loss(valY, uncalibrated)}')\n",
    "print(f'Sigmoid calibration: {brier_score_loss(valY, calibrated_gb1)}')\n",
    "print(f'Sigmoid calibration: {brier_score_loss(valY, calibrated_gb2)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>IsMale</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>BalanceByProducts</th>\n",
       "      <th>SalaryByProducts</th>\n",
       "      <th>meta_svm</th>\n",
       "      <th>meta_gb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101348.880</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>83807.860000</td>\n",
       "      <td>112542.580</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>53220.266667</td>\n",
       "      <td>37977.190</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46913.315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>125510.820000</td>\n",
       "      <td>79084.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  IsMale  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France       0   42       2       0.00              1   \n",
       "1          608     Spain       0   41       1   83807.86              1   \n",
       "2          502    France       0   42       8  159660.80              3   \n",
       "3          699    France       0   39       1       0.00              2   \n",
       "4          850     Spain       0   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  BalanceByProducts  \\\n",
       "0          1               1        101348.88       1           0.000000   \n",
       "1          0               1        112542.58       0       83807.860000   \n",
       "2          1               0        113931.57       1       53220.266667   \n",
       "3          0               0         93826.63       0           0.000000   \n",
       "4          1               1         79084.10       0      125510.820000   \n",
       "\n",
       "   SalaryByProducts  meta_svm  meta_gb  \n",
       "0        101348.880         1        0  \n",
       "1        112542.580         0        0  \n",
       "2         37977.190         1        1  \n",
       "3         46913.315         0        0  \n",
       "4         79084.100         0        0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metasvm = clf1.predict(Xs)\n",
    "metagb = clf2.predict(Xs)\n",
    "\n",
    "metasvm2 = clf1.predict(valXs)\n",
    "metagb2 = clf2.predict(valXs)\n",
    "train3 = train2.assign(meta_svm=metasvm, meta_gb=metagb)\n",
    "valX2 = valX.assign(meta_svm=metasvm2, meta_gb=metagb2)\n",
    "train3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>IsMale</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>BalanceByProducts</th>\n",
       "      <th>SalaryByProducts</th>\n",
       "      <th>meta_svm</th>\n",
       "      <th>meta_gb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5766</th>\n",
       "      <td>556</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>125909.85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>95124.40</td>\n",
       "      <td>125909.850</td>\n",
       "      <td>95124.400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4498</th>\n",
       "      <td>570</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>131406.56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47952.45</td>\n",
       "      <td>131406.560</td>\n",
       "      <td>47952.450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3636</th>\n",
       "      <td>663</td>\n",
       "      <td>Spain</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>103430.11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36479.27</td>\n",
       "      <td>51715.055</td>\n",
       "      <td>18239.635</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6363</th>\n",
       "      <td>678</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>113794.22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16618.76</td>\n",
       "      <td>113794.220</td>\n",
       "      <td>16618.760</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7523</th>\n",
       "      <td>814</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130853.03</td>\n",
       "      <td>0.000</td>\n",
       "      <td>65426.515</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  IsMale  Age  Tenure    Balance  NumOfProducts  \\\n",
       "5766          556    France       1   40       5  125909.85              1   \n",
       "4498          570    France       1   30       2  131406.56              1   \n",
       "3636          663     Spain       1   31       4  103430.11              2   \n",
       "6363          678     Spain       0   40       4  113794.22              1   \n",
       "7523          814     Spain       0   72       2       0.00              2   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  BalanceByProducts  \\\n",
       "5766          1               1         95124.40         125909.850   \n",
       "4498          1               1         47952.45         131406.560   \n",
       "3636          0               1         36479.27          51715.055   \n",
       "6363          1               0         16618.76         113794.220   \n",
       "7523          0               1        130853.03              0.000   \n",
       "\n",
       "      SalaryByProducts  meta_svm  meta_gb  \n",
       "5766         95124.400         0        0  \n",
       "4498         47952.450         0        0  \n",
       "3636         18239.635         0        0  \n",
       "6363         16618.760         0        0  \n",
       "7523         65426.515         0        0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valX2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now re split-scale-recombine our datasets, then train a fancy new model! :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempt3 = pandas.get_dummies(train3)\n",
    "tr3n, tr3c = re_order_unbind_2(tempt3)\n",
    "train4 = scale_rebind(tr3n, tr3c)\n",
    "\n",
    "tempvalx3 = pandas.get_dummies(valX2)\n",
    "v3n, v3c = re_order_unbind_2(tempvalx3)\n",
    "valX3 = scale_rebind(v3n, v3c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "models2 = {'svm': svm.SVC(), 'svm_poly_2': svm.SVC(), 'es': es.RandomForestClassifier(), 'ada': es.AdaBoostClassifier(), 'gb': es.GradientBoostingClassifier()}\n",
    "svm2 = {'C': [0.1, 0.3, 0.5, 1], 'kernel': ['linear', 'rbf'], 'gamma': ['auto', 0.3, 0.1, 0.7], 'probability': [True], 'class_weight': ['balanced', None], 'random_state': [74]}\n",
    "svmpoly2 = {'C': [0.1, 0.3, 0.5, 1], 'kernel': ['poly'], 'degree': [3,4,5], 'gamma': ['auto', 0.3, 0.1, 0.7], 'probability': [True], 'class_weight': ['balanced', None], 'random_state': [74]}\n",
    "forest2 = {'n_estimators': [10, 50, 100, 200], 'max_features': ['auto', 0.5, 0.8], 'class_weight': ['balanced', None]}\n",
    "ada2 = {'n_estimators': [30, 40, 50, 80, 100, 150], 'learning_rate': [0.1, 0.2, 0.3, 0.35, 0.25], 'random_state': [74]}\n",
    "# gb2 = {}\n",
    "params2 = {'svm': svm2, 'svm_poly_2': svmpoly2, 'es': forest2, 'ada': ada2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model: svm\n",
      "{'C': 1, 'class_weight': None, 'gamma': 0.1, 'kernel': 'rbf', 'probability': True, 'random_state': 74}\n",
      "5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.95      0.90       769\n",
      "          1       0.69      0.43      0.53       201\n",
      "\n",
      "avg / total       0.83      0.84      0.83       970\n",
      "\n",
      "\n",
      "\n",
      "Testing model: svm_poly_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-64:\n",
      "Process ForkPoolWorker-56:\n",
      "Process ForkPoolWorker-61:\n",
      "Process ForkPoolWorker-58:\n",
      "Process ForkPoolWorker-54:\n",
      "Process ForkPoolWorker-63:\n",
      "Process ForkPoolWorker-57:\n",
      "Process ForkPoolWorker-52:\n",
      "Process ForkPoolWorker-59:\n",
      "Process ForkPoolWorker-50:\n",
      "Process ForkPoolWorker-51:\n",
      "Process ForkPoolWorker-60:\n",
      "Process ForkPoolWorker-55:\n",
      "Process ForkPoolWorker-62:\n",
      "Process ForkPoolWorker-49:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 362, in get\n",
      "    return recv()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-3172845e2636>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                        \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                       refit='accuracy')\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m                     \u001b[0;31m# scheduling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mabort_everything\u001b[0;34m(self, ensure_ready)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;34m\"\"\"Shutdown the pool and restart a new one with the same parameters\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             self.configure(n_jobs=self.parallel.n_jobs, parallel=self.parallel,\n",
      "\u001b[0;32m~/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;34m\"\"\"Shutdown the process or thread pool\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultiprocessingBackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOBLIB_SPAWNED_PROCESS\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOBLIB_SPAWNED_PROCESS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# terminate does a join()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m                 \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMemmapingPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_terminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wr, _finalizer_registry, sub_debug, getpid)\u001b[0m\n\u001b[1;32m    184\u001b[0m                 sub_debug('finalizer calling %s with args %s and kwargs %s',\n\u001b[1;32m    185\u001b[0m                           self._callback, self._args, self._kwargs)\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weakref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_terminate_pool\u001b[0;34m(cls, taskqueue, inqueue, outqueue, pool, worker_handler, task_handler, result_handler, cache)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'helping task handler/workers to finish'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_help_stuff_finish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minqueue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mresult_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_help_stuff_finish\u001b[0;34m(inqueue, task_handler, size)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;31m# task_handler may be blocked trying to put items on inqueue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'removing tasks from inqueue until task handler finished'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0minqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mtask_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0minqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for model, parameters in params2.items():\n",
    "    print()\n",
    "    print()\n",
    "    print(f'Testing model: {model}')\n",
    "    clf = GridSearchCV(estimator=models2[model],\n",
    "                       param_grid=parameters,\n",
    "                       cv=5,\n",
    "                       scoring='accuracy',\n",
    "                       n_jobs=-1,\n",
    "                      refit='accuracy')\n",
    "    clf.fit(train4, Y)\n",
    "    print(clf.best_params_)\n",
    "    print(clf.n_splits_)\n",
    "    est = clf.best_estimator_\n",
    "    y_pred = est.predict(valX3)\n",
    "    print(classification_report(valY, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: [0.85746995 0.85746995 0.85100287 0.85787966 0.85616046]\n",
      "F1: [0.64680851 0.64780764 0.64383562 0.65070423 0.64598025]\n",
      "Precision: [0.65517241 0.65428571 0.62834225 0.65254237 0.64872521]\n",
      "Recall: [0.63865546 0.64145658 0.66011236 0.6488764  0.64325843]\n",
      "Roc AUC: [0.87155956 0.86360962 0.87326991 0.8617023  0.85983166]\n",
      "Log Loss: [0.70244788 0.69901829 0.92062161 0.74426235 0.84080877]\n",
      "\n",
      "Accuracy average: 0.8559965753817842\n",
      "F1 average: 0.6470272488428235\n",
      "Precision average: 0.6478135918828135\n",
      "Recall average: 0.6464718471658326\n",
      "Roc AUC average: 0.8659946103895901\n",
      "Log loss average: 0.7814317805733448\n",
      "\n",
      "N.B. Higher value for log loss == bad. Better values approach 0\n"
     ]
    }
   ],
   "source": [
    "meta_scoring = ['f1', 'recall', 'precision', 'accuracy', 'roc_auc', 'neg_log_loss']\n",
    "estimator = svm.SVC()\n",
    "scores = cross_validate(estimator, train4, Y, cv=5, scoring=meta_scoring)\n",
    "# clf2 = clf2.fit(X2, Y)\n",
    "# res = clf2.predict(X2)\n",
    "print(f'Accuracy: {scores[\"test_accuracy\"]}')\n",
    "print(f'F1: {scores[\"test_f1\"]}')\n",
    "print(f'Precision: {scores[\"test_precision\"]}')\n",
    "print(f'Recall: {scores[\"test_recall\"]}')\n",
    "print(f'Roc AUC: {scores[\"test_roc_auc\"]}')\n",
    "print(f'Log Loss: {scores[\"test_neg_log_loss\"]*-1}')\n",
    "print()\n",
    "print(f'Accuracy average: {scores[\"test_accuracy\"].mean()}')\n",
    "print(f'F1 average: {scores[\"test_f1\"].mean()}')\n",
    "print(f'Precision average: {scores[\"test_precision\"].mean()}')\n",
    "print(f'Recall average: {scores[\"test_recall\"].mean()}')\n",
    "print(f'Roc AUC average: {scores[\"test_roc_auc\"].mean()}')\n",
    "print(f'Log loss average: {scores[\"test_neg_log_loss\"].mean()*-1}')\n",
    "print()\n",
    "print('N.B. Higher value for log loss == bad. Better values approach 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = np.concatenate(Xs, valXs)\n",
    "target = np.co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
