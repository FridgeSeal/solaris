{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import seaborn as sb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.feature_extraction as fe\n",
    "import sklearn.preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, GridSearchCV\n",
    "import sklearn.neighbors as nhb\n",
    "import sklearn.ensemble as es\n",
    "import sklearn.tree as tree\n",
    "from sklearn import svm\n",
    "import sklearn.naive_bayes as nb\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.metrics import classification_report, fbeta_score, make_scorer, log_loss, accuracy_score, roc_curve, brier_score_loss, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "import sklearn.calibration as cl\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pandas.read_csv('data/account_histroy_data.csv')\n",
    "test = pandas.read_csv('data/existing_account.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(labels = ['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "train = train.replace({'Gender': {'Female': 0, 'Male': 1}})\n",
    "train = train.rename(columns={'Gender': 'IsMale'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd981d4f9b0>"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matplotlib.style.use('ggplot')\n",
    "train['IsMale'].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial analysis\n",
    "\n",
    "* `RowNumber`, `CustomerID` and `Surname` can be dropped \n",
    "* `CreditScore` whilst numerical should be treated more like a ordinal variable. Nice and normal distribution. No missing values\n",
    "* `Age` is nicely behaved: no missing values, nice and finite, nice and normally distributed\n",
    "* `Tenure` is similarly nicely behaved: no missing values, finitely bounded and practically uniformally distributed. What does this variable represent? Age of account?\n",
    "* `Balance` is a bit more interesting: there's a large spike at ~<= 30k and then a normally distributed group centered at just over 100k. This suggests 2 separate populations. No na values\n",
    "* `NumOfProducts` is uninteresting: no missing values, all integers in [1,4]. All same order of magnitude\n",
    "* `HasCrCard` binary variable indicating credit card ownership. No missing values. Distribution of both classes is same order of magnitude, positive value (`1`) outweighs `0` value by about 4k occurences.\n",
    "* `IsActiveMember` binary variable. Practically class sizes. No missing values.\n",
    "* `EstimatedSalary` nicely behaved: uniform distribution with no missing values and all values in the same order of magnitude.\n",
    "* `Exited` Target variable. 1 indicates customer left, inbalanced classes with most cases in the \"stayed\" category.\n",
    "\n",
    "# Potential process\n",
    "\n",
    "* Given we don't have to worry about missing values, send the data straight to an `sklearn DictVectoriser` (as we want to track column names) followed by `OneHotEncoder` to handle binary variables that \n",
    "* This will automatically handle binarising our categorical variables.\n",
    "* Most variables were normally or uniformally distributed, so standard scaling should be sufficient, but test with robust scaling as well.\n",
    "* We've got enough data points that we can comfortable affort to slice off a portion of the dataset as a validation set. This can be done post scaling, pre test-train split. This will help prevent overfitting.\n",
    "* The class imbalance isn't too bad (they're both on the same order of magnitude), but it would be worth testing over/under/synthetic sampling approaches anyways.\n",
    "* We're treating this as a classification exercise, so let's run it across Naive Bayes, some forests of trees, gradient boosting, SVM's. As a baseline/sanity check let's run super basic logistic and single-tree models as well. ~~Bigger~~ Fancier isn't always better.\n",
    "* Model stacking and voting classifiers (soft and hard) are also worth investigating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>IsMale</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [CreditScore, Geography, IsMale, Age, Tenure, Balance, NumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary, Exited]\n",
       "Index: []"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['EstimatedSalary'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd981d77c18>"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = train[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited']].corr()\n",
    "camp = sb.diverging_palette(220, 10, as_cmap=True)\n",
    "sb.heatmap(corr, cmap=camp, square=True, linewidths=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Matrix\n",
    "While it appears pretty uniform at first glance, there's some interesting stuff lurking here: whilst most of the variables exhibit near 0 correlation, there's some positive correlation between `age` and `exited` and some (relatively) strong negative correlation between `NumOfProducts` and `Balance`. There's also a weak negative correlation between `IsActiveMember` and `Exited`; possibly too weak to be useful, but worth keeping in mind.\n",
    "\n",
    "# Feature Engineering\n",
    "Add some features that we think might add some extra information/structure to the dataset - models and feature selection will drop them back out if they turn out to not be useful.\n",
    "* Balance / NumOfProducts?\n",
    "* EstimatedSalary / NumOfProducts\n",
    "* NumOfProducts / Tenure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.assign(\n",
    "    BalanceByProducts=(train['Balance'] / train['NumOfProducts']), \n",
    "    SalaryByProducts=(train['EstimatedSalary'] / train['NumOfProducts']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's slice off a validation set now so we can completely isolate it from the train and test data.\n",
    "validation = train[['CreditScore', 'Geography', 'IsMale', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember',\n",
    "                    'EstimatedSalary','BalanceByProducts','SalaryByProducts', 'Exited']].sample(frac=0.1)\n",
    "train2 = train[~train.index.isin(validation.index)]# Drop the validation values from the primary train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>IsMale</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>BalanceByProducts</th>\n",
       "      <th>SalaryByProducts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101348.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>83807.860000</td>\n",
       "      <td>112542.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>53220.266667</td>\n",
       "      <td>37977.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46913.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>125510.820000</td>\n",
       "      <td>79084.100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  IsMale  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France       0   42       2       0.00              1   \n",
       "1          608     Spain       0   41       1   83807.86              1   \n",
       "2          502    France       0   42       8  159660.80              3   \n",
       "3          699    France       0   39       1       0.00              2   \n",
       "4          850     Spain       0   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  BalanceByProducts  \\\n",
       "0          1               1        101348.88       1           0.000000   \n",
       "1          0               1        112542.58       0       83807.860000   \n",
       "2          1               0        113931.57       1       53220.266667   \n",
       "3          0               0         93826.63       0           0.000000   \n",
       "4          1               1         79084.10       0      125510.820000   \n",
       "\n",
       "   SalaryByProducts  \n",
       "0        101348.880  \n",
       "1        112542.580  \n",
       "2         37977.190  \n",
       "3         46913.315  \n",
       "4         79084.100  "
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_target(data):\n",
    "    cols = data.columns\n",
    "    target = data['Exited']\n",
    "    rem = data[cols.drop('Exited')]\n",
    "    return rem, target\n",
    "\n",
    "def re_order_unbind(data): \n",
    "    re_ordering = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary', 'BalanceByProducts', 'SalaryByProducts',\n",
    "                   'IsMale', 'HasCrCard', 'IsActiveMember', 'Geography_France', 'Geography_Germany', 'Geography_Spain',]\n",
    "    num_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary','BalanceByProducts', 'SalaryByProducts']\n",
    "    cat_cols = ['IsMale', 'HasCrCard', 'IsActiveMember', 'Geography_France', 'Geography_Germany', 'Geography_Spain']\n",
    "    data = data[re_ordering]\n",
    "    numerical = data[num_cols]\n",
    "    categorical = data[cat_cols]\n",
    "    return numerical, categorical\n",
    "\n",
    "def re_order_unbind_2(data):  # Should have just parametised the first function, oh well\n",
    "    re_ordering = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary', 'BalanceByProducts', 'SalaryByProducts',\n",
    "                   'IsMale', 'HasCrCard', 'IsActiveMember', 'Geography_France', 'Geography_Germany', 'Geography_Spain', 'meta_svm', 'meta_gb']\n",
    "    num_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary','BalanceByProducts', 'SalaryByProducts']\n",
    "    cat_cols = ['IsMale', 'HasCrCard', 'IsActiveMember', 'Geography_France', 'Geography_Germany', 'Geography_Spain', 'meta_svm', 'meta_gb']\n",
    "    data = data[re_ordering]\n",
    "    numerical = data[num_cols]\n",
    "    categorical = data[cat_cols]\n",
    "    return numerical, categorical\n",
    "\n",
    "def scale_rebind(num, cat):\n",
    "    scalefn = pp.StandardScaler()\n",
    "    scaled = scalefn.fit_transform(num)\n",
    "    return np.concatenate([scaled, cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lots of algorithms expect (and perform better) when data is in the same scale. However, it doesn't much sense to scale categorical variables, so we re-order the dataset for ease of interpretation then separate it\n",
    "# into numerical and categorical sections, scale the numerical data and then rejoin everything back into the one dataset. Turning it into a function means we have a nice, single place to change our scaling type\n",
    "# later if we want to test other types.\n",
    "\n",
    "X,Y = sep_target(train2)\n",
    "tempX = pandas.get_dummies(X)  # Splits categorical/text columns containing n categories into n binary variables\n",
    "Xn, Xc = re_order_unbind(tempX)\n",
    "Xs = scale_rebind(Xn, Xc)\n",
    "\n",
    "valX, valY = sep_target(validation)\n",
    "temp_valX = pandas.get_dummies(valX)\n",
    "valXn, valXc = re_order_unbind(temp_valX)\n",
    "valXs = scale_rebind(valXn, valXc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thoughts on ML/fitting process\n",
    "\n",
    "We are trying to predict whether a user will leave/stop being a customer. We have a large choice of metrics with which to evaluate estimator performance. Measuring model confidence via probabilities would be ideal as it will let us generate the `log-loss` metric which means we can optimise for an estimator that is not \"confidently wrong\" which would result in lost clients. Outputting probabilities is also useful because it would give the sales/retention/etc team the ability to prioritise certain customers based on how likely they are to churn. `F1` or `Fbeta` score would probably be the next best metric to evaluate with. Weighting for `Fbeta` could go either way. On one hand we don't want to raise false-positives on clients that weren't going to churn because this wastes sales' effort (but has no negative effect on the customer), but weighting too heavily for precision could lead to potential churn-customers being lost in order for the model to preserve the accuracy of the ones it is confident in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'svm': svm.SVC(),\n",
    "    'svm_poly': svm.SVC(),\n",
    "    'knn': nhb.KNeighborsClassifier(),\n",
    "    'naive_bayes': nb.GaussianNB(),\n",
    "#     'decision_tree': tree.DecisionTreeClassifier(),\n",
    "    'random_forest': es.RandomForestClassifier(),\n",
    "    'adaBoost': es.AdaBoostClassifier(),\n",
    "    'Gradient_Boosting': es.GradientBoostingClassifier(),\n",
    "    'Logistic_Regression': lm.LogisticRegression()\n",
    "    #'Voting classifier'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'C': 0.5, 'class_weight': 'balanced', 'coef0': 0.4, 'degree': 3, 'gamma': 0.3, 'kernel': 'poly', 'probability': True, 'random_state': 74}\n",
    "svm_params = {'C': [1, 0.5, 0.1], 'kernel': ['linear', 'rbf',], 'gamma': ['auto', 0.3], \n",
    "             'probability': [True], 'class_weight': ['balanced', None], 'random_state': [74]}\n",
    "svm_poly_params = {'C': [0.5, 0.8, 0.25], 'kernel': ['poly'], 'degree': [2,3,5], 'gamma': ['auto', 0.1, 0.3], 'coef0': [0, 0.4, 0.6],\n",
    "                'probability': [True], 'class_weight': ['balanced', None], 'random_state': [74]},\n",
    "knn_params = {'n_neighbors': [3, 5, 9, 10, 15], 'weights': ['uniform', 'distance'], 'algorithm': ['kd_tree']}\n",
    "nb_params = None\n",
    "tree_params = None\n",
    "forest_params = {'n_estimators': [50, 80, 150, 200, 250], 'max_features': ['auto', None, 0.5,0.8], 'min_samples_split': [0.3, 0.5, 0.8],\n",
    "                'bootstrap': [True, False], 'n_jobs': [-1], 'random_state': [74], 'class_weight': ['balanced', None, 'balanced_subsample'], 'warm_start': [False]}\n",
    "ada_params = {'n_estimators': [30, 40, 50, 80, 100, 150], 'learning_rate': [0.1, 0.2, 0.3, 0.35, 0.25], 'random_state': [74]},\n",
    "gb_params = {'learning_rate': [0.1, 0.05], 'n_estimators': [100, 200, 300, 400, 500, 600], 'max_depth': [3, 6, 10], 'min_samples_split': [0.5, 0.3, 0.75],\n",
    "            'min_samples_leaf': [1,3, 0.5, 0.2], 'subsample': [0.5, 1], 'max_features': [None, 'auto'], 'random_state': [74]}\n",
    "logistic_params = {'C': [1, 0.75, 0.6, 0.4], 'class_weight': ['balanced', None], 'random_state': [74], 'max_iter': [300], 'warm_start': [True, False]}\n",
    "voting_params = None\n",
    "params = {#'svm': svm_params,\n",
    "          'svm_poly': svm_poly_params,\n",
    "          'knn': knn_params,\n",
    "#           'decision TREE': tree_params,\n",
    "          #'random_forest': forest_params,\n",
    "          'adaBoost': ada_params,\n",
    "          'Gradient_Boosting': gb_params,\n",
    "          'Logistic_Regression': logistic_params}\n",
    "#           'Voting classifier': voting_params}  # Leave this one out until we've got some good models to vote with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model: svm_poly\n",
      "{'C': 0.25, 'class_weight': 'balanced', 'coef0': 0.4, 'degree': 3, 'gamma': 0.3, 'kernel': 'poly', 'probability': True, 'random_state': 74}\n",
      "5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.80      0.85       758\n",
      "          1       0.49      0.68      0.57       212\n",
      "\n",
      "avg / total       0.81      0.78      0.79       970\n",
      "\n",
      "\n",
      "\n",
      "Testing model: knn\n",
      "{'algorithm': 'kd_tree', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.92      0.88       758\n",
      "          1       0.59      0.43      0.50       212\n",
      "\n",
      "avg / total       0.79      0.81      0.80       970\n",
      "\n",
      "\n",
      "\n",
      "Testing model: adaBoost\n",
      "{'learning_rate': 0.35, 'n_estimators': 150, 'random_state': 74}\n",
      "5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.96      0.90       758\n",
      "          1       0.73      0.39      0.51       212\n",
      "\n",
      "avg / total       0.82      0.84      0.82       970\n",
      "\n",
      "\n",
      "\n",
      "Testing model: Gradient_Boosting\n",
      "{'learning_rate': 0.05, 'max_depth': 6, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 0.3, 'n_estimators': 600, 'random_state': 74, 'subsample': 1}\n",
      "5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.96      0.91       758\n",
      "          1       0.74      0.43      0.55       212\n",
      "\n",
      "avg / total       0.83      0.84      0.83       970\n",
      "\n",
      "\n",
      "\n",
      "Testing model: Logistic_Regression\n",
      "{'C': 0.4, 'class_weight': 'balanced', 'max_iter': 300, 'random_state': 74, 'warm_start': True}\n",
      "5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.73      0.80       758\n",
      "          1       0.40      0.65      0.50       212\n",
      "\n",
      "avg / total       0.78      0.71      0.73       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We're going to build the models to optimise for recall first, then model stack with the best one(s) and then build a 2nd generation of models optimising for precision/log-loss.\n",
    "for model, parameters in params.items():\n",
    "    print()\n",
    "    print()\n",
    "    print(f'Testing model: {model}')\n",
    "    clf = GridSearchCV(estimator=models[model],\n",
    "                       param_grid=parameters,\n",
    "                       cv=5,\n",
    "                       scoring='recall',\n",
    "                       n_jobs=-1,\n",
    "                      refit='recall')\n",
    "    clf.fit(Xs, Y)\n",
    "    print(clf.best_params_)\n",
    "    print(clf.n_splits_)\n",
    "    est = clf.best_estimator_\n",
    "    y_pred = est.predict(valXs)\n",
    "    print(classification_report(valY, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Results:\n",
    "* Plain SVM's performed average at best, with middling precision but good recall: `0.49` and `0.72` respectively and `0.58` for the f1 score.\n",
    "* Polynomial SVM's performed better with improvements to precision, recall and f1 score: `0.5`, `0.74` and `0.6` respectively.\n",
    "Optimising precision and recall is a tradeoff, but for our case, because we don't want to risk losing customers, we want to bias slightly towards recall.\n",
    "* Plain random forests and adaBoost haven't been too suitable for our use-case: they both perform exceedingly well with regards to precision - scoring `0.81` and `0.94` respectively but very poorly when it comes to recall with both models scoring `<= 0.1` for the target value (left). This isn't ideal as it means that whilst their predictions for customers leaving are accurate (they're generating very few false positives), they're essentially underestimating/underpredicting the number of customers who would leave. That is, in production, they would not flag a large percentage of customers who are about to leave.\n",
    "* There is an upside, we can still make use of the high precision of these models by using model-stacking. This is where we'll use a model (adaBoost and svm_poly in this case) to generate predictions for all samples in the greater training and validation set (`Xs` and `valXs`) and these add a column in each dataset. We'll then train another model using this new dataset, this allows us to guide/help successive models with extra information.\n",
    "\n",
    "# Best models so far:\n",
    "Polynomial SVM (for best recall)\n",
    "```\n",
    "{'C': 0.25, 'class_weight': 'balanced', 'coef0': 0.4, 'degree': 3, 'gamma': 0.3, 'kernel': 'poly', 'probability': True, 'random_state': 74}\n",
    "5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          0       0.90      0.80      0.85       758\n",
    "          1       0.49      0.68      0.57       212\n",
    "\n",
    "avg / total       0.81      0.78      0.79       970``` \n",
    "\n",
    "\n",
    "Gradient Boosting Trees  (for best precision)\n",
    "```\n",
    "{'learning_rate': 0.05, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 0.3, 'n_estimators': 200, 'random_state': 74, 'subsample': 1}\n",
    "5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          0       0.87      0.95      0.91       767\n",
    "          1       0.72      0.45      0.55       203\n",
    "\n",
    "avg / total       0.84      0.85      0.83       970```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "#Let's roll with the polynomial SVM for now, as that seems to have the best balance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison\n",
    "\n",
    "We've got a couple of models that perform quite well on the validation set, to compare them further we'll evaluate their scores in a couple of other metrics, notably log-loss, ROC area-under-curve and overall accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check log-loss and ROC-AUC stats for these, then see if their probability-calibrated versions yield any improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_scoring(validation, y_true, model):\n",
    "    y_predicted = model.predict(validation)\n",
    "    probs_predicted = model.predict_proba(validation)\n",
    "    log_loss_res = log_loss(y_true=y_true, y_pred=probs_predicted[:, 1])\n",
    "    roc_auc_res = roc_curve(y_true=y_true, y_score=probs_predicted[:, 1])\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_predicted)\n",
    "    # Regenerate precision and recall just so we can compare everything in one place\n",
    "    prec = precision_score(y_true=y_true, y_pred=y_predicted)\n",
    "    rec = recall_score(y_true=y_true, y_pred=y_predicted)\n",
    "    cnfsn_matrix = confusion_matrix(y_true=y_true, y_pred=y_predicted)\n",
    "    tn, fp, fn, tp = cnfsn_matrix.ravel()\n",
    "#     Informedness = Sensitivity + Specificity − 1\n",
    "    informedness = rec + (tp / (fp + tn)) - 1\n",
    "#     Markedness = PPV + NPV − 1\n",
    "    markedness = prec + (tn / (tn + fn)) - 1\n",
    "    print(f'Log-loss: {log_loss_res}')\n",
    "#     print(f'ROC-AUC: {roc_auc_res}') Exclude this for now, as a plot of the ROC curve is probably more useful\n",
    "#     Add ROC curve plots\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {prec}')\n",
    "    print(f'Recall: {rec}')\n",
    "#     Add (normalised) confusion matrix plots here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,13.5095,'Predicted label')"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "temp = clf2.predict(valXs)\n",
    "cfnm = confusion_matrix(valY, temp)\n",
    "cfnm = cfnm/cfnm.sum(axis=1)[:, np.newaxis]\n",
    "plt.imshow(cfnm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "plt.xticks([0.5], (0,1), rotation=45)\n",
    "plt.yticks([0.5], (0,1), rotation=45)\n",
    "thold = cfnm.max() / 2.\n",
    "for i, j in itertools.product(range(cfnm.shape[0]), range(cfnm.shape[1])):\n",
    "    plt.text(j, i, format(cfnm[i, j], '.2f'), horizontalalignment='center', color='white' if cfnm[i,j] > thold else 'black')\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      "Log-loss: 0.39356876258089474\n",
      "Accuracy: 0.7762886597938145\n",
      "Precision: 0.4915254237288136\n",
      "Recall: 0.6839622641509434\n",
      "\n",
      "Gradient Boosting:\n",
      "Log-loss: 0.36574992317541327\n",
      "Accuracy: 0.8391752577319588\n",
      "Precision: 0.7222222222222222\n",
      "Recall: 0.42924528301886794\n"
     ]
    }
   ],
   "source": [
    "svc = {'C': 0.25, 'class_weight': 'balanced', 'coef0': 0.4, 'degree': 3, 'gamma': 0.3, 'kernel': 'poly', 'probability': True, 'random_state': 74}\n",
    "gbc = {'learning_rate': 0.05, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 0.3, 'n_estimators': 200, 'random_state': 74, 'subsample': 1}\n",
    "clf1 = svm.SVC().set_params(**svc).fit(Xs, Y)\n",
    "clf2 = es.GradientBoostingClassifier().set_params(**gbc).fit(Xs, Y)\n",
    "print('SVM:')\n",
    "basic_scoring(valXs, valY, clf1)\n",
    "print()\n",
    "print('Gradient Boosting:')\n",
    "basic_scoring(valXs, valY, clf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models exhibit some reasonably nice results. The SVM has been optimised for recall, and the gradient boost has been optimised for accuracy.\n",
    "We'll run variable importance using the gradient boosting model and see if there's any variables we can drop. We'll then model stack using both models (i.e. add both models predictions to the training and validation sets) and then re-run with a model trained for accuracy or log-loss. Why model stack? Why isn't the gradient boosting/SVM model good enough on its own? In my opinion, the GB isn't good enough by itself because it misses a non-trivial portion of the positive cases. In a production environment, this would mean that while it's predictions for customers that will exit will be correct, there is a significant number of customers that it would miss. \n",
    "This is partially mitigated by low log-loss, which can be affected by outputting the probability of exit, rather than a yes/no for exit and then ranking customers by this probability because the models low log-loss translates into low confidence on incorrect cases which means that they will be near a decision boundary implying a moderate probability. This means Sales/retention/etc has more information on which customers to target rather than a bright-line yes/no. With these constraints/approaches in place, we could arguably stop here and just use the GB model with the mitigations in place, but I think we should go further.\n",
    "\n",
    "The models have different strengths, so we're going to use both to build \"meta\" columns for our 2nd generation model.\n",
    "\n",
    "* log-loss, which measures how \"confident\" a model is about incorrect results is quite an important metric: ideally, when the model incorrectly classifies a customer as \"staying\", we want it to do so in such a way that has these cases near the decision boundary (i.e. the probability of that case being \"stay\" is low\", but not low enough to be cleanly classified as \"exiting\"). This means that when we rank the customers by probability of leaving, these customers will be near the middle, giving us more information to make a decision about who to follow up with beyond \"will exit/won't exit\".\n",
    "    * Both models score well in this metric: `0.384` and `0.355` for the SVM and Gradient Boosting respectively. A lower score is better, with the metric having a lower bound at 0, representing a perfect score, as such, the Gradient Boosting models performs the best here.\n",
    "* Accuracy measures how many correct classifications were made across both classes. It is best viewed in combination with precision and recall to get a full picture of how well a model does what you wish (for example, you want an accurate model, but you . Higher scores are better, with the metric `[0,1]` bounded.\n",
    "    * Both models perform well under this metric, with the SVM having an every so slight- likely statistically inconsequential - lead.\n",
    "* Precision and Recall are a pair of metrics that measure \"quality\" and \"quantity\" respectively. Precision measures the fraction of cases marked as \"positive\" that were actually \"positive\". Recall measures the fraction of \"positive\" cases that were marked as \"positive\" by the classifier. Optimising a given classifier is a balance between these 2 metrics, as recall can be improved by essentially marking more cases as positive (which drives down precision) and precision can be boosted by essentially tightening decision boundaries to return fewer results but only correct ones (which would drive down recall, because you would be excluding valid \"positive\" cases). Once again, both metrics are `[0,1]` bounded and higher is better.\n",
    "    * Precision for both classifiers is very good: `0.752` and `0.722` for the SVM and the Gradient Boosted models respectively. Both models also score similarly well for recall with the Gradient Boosting model performing slightly better than the SVM in this regard with a score of `0.448` vs `0.418`.\n",
    "    \n",
    "* Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss: 8.296576935205211\n",
      "Log-loss: 5.376689503838744\n",
      "No calibration SVC: 0.11990238439982598\n",
      "Sigmoid calibration: 0.11545138732209186\n",
      "Sigmoid calibration: 0.12018441325708971\n",
      "No calibration Gradient Boosting: 0.11048031215674682\n",
      "Sigmoid calibration: 0.11118911776845422\n",
      "Sigmoid calibration: 0.11178568295734097\n"
     ]
    }
   ],
   "source": [
    "# Maybe table the probability calibration for now, as we really don't care _that_ much for these models.\n",
    "\n",
    "svc = {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.3, 'kernel': 'rbf', 'probability': True, 'random_state': 74}\n",
    "gbc = {'learning_rate': 0.1, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 0.3, 'n_estimators': 600, 'random_state': 74, 'subsample': 1}\n",
    "clf1 = svm.SVC().set_params(**svc).fit(Xs, Y)\n",
    "clf2 = es.GradientBoostingClassifier().set_params(**gbc).fit(Xs, Y)\n",
    "basic_scoring(valXs, valY, clf1)\n",
    "basic_scoring(valXs, valY, clf2)\n",
    "\n",
    "svm_pc1 = cl.CalibratedClassifierCV(base_estimator=svm.SVC(), cv=5, method='sigmoid')\n",
    "svm_pc2 = cl.CalibratedClassifierCV(base_estimator=svm.SVC().set_params(**svc), cv=5, method='sigmoid').fit(Xs, Y)\n",
    "svm_pc3 = cl.CalibratedClassifierCV(base_estimator=clf1, cv='prefit', method='sigmoid')\n",
    "gb_pc1 = cl.CalibratedClassifierCV(base_estimator=es.GradientBoostingClassifier(), cv=5, method='sigmoid').fit(Xs, Y)\n",
    "gb_pc2 = cl.CalibratedClassifierCV(base_estimator=es.GradientBoostingClassifier().set_params(**gbc), cv=5, method='sigmoid').fit(Xs, Y)\n",
    "\n",
    "uncalibratedSVM = clf1.predict_proba(valXs)[:,1]\n",
    "uncalibratedGB = clf2.predict_proba(valXs)[:,1]\n",
    "calibrated_svm1 = svm_pc1.fit(Xs, Y).predict_proba(valXs)[:, 1]\n",
    "calibrated_svm2 = svm_pc2.fit(Xs, Y).predict_proba(valXs)[:, 1]\n",
    "calibrated_gb1 = gb_pc1.fit(Xs, Y).predict_proba(valXs)[:,1]\n",
    "calibrated_gb2 = gb_pc2.fit(Xs, Y).predict_proba(valXs)[:,1]\n",
    "\n",
    "print(f'No calibration SVC: {brier_score_loss(valY, uncalibratedSVM)}')\n",
    "print(f'Sigmoid calibration: {brier_score_loss(valY, calibrated_svm1)}')\n",
    "print(f'Sigmoid calibration: {brier_score_loss(valY, calibrated_svm2)}')\n",
    "print(f'No calibration Gradient Boosting: {brier_score_loss(valY, uncalibrated)}')\n",
    "print(f'Sigmoid calibration: {brier_score_loss(valY, calibrated_gb1)}')\n",
    "print(f'Sigmoid calibration: {brier_score_loss(valY, calibrated_gb2)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>IsMale</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>BalanceByProducts</th>\n",
       "      <th>SalaryByProducts</th>\n",
       "      <th>meta_svm</th>\n",
       "      <th>meta_gb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101348.880</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>83807.860000</td>\n",
       "      <td>112542.580</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>53220.266667</td>\n",
       "      <td>37977.190</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46913.315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>125510.820000</td>\n",
       "      <td>79084.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  IsMale  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France       0   42       2       0.00              1   \n",
       "1          608     Spain       0   41       1   83807.86              1   \n",
       "2          502    France       0   42       8  159660.80              3   \n",
       "3          699    France       0   39       1       0.00              2   \n",
       "4          850     Spain       0   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  BalanceByProducts  \\\n",
       "0          1               1        101348.88       1           0.000000   \n",
       "1          0               1        112542.58       0       83807.860000   \n",
       "2          1               0        113931.57       1       53220.266667   \n",
       "3          0               0         93826.63       0           0.000000   \n",
       "4          1               1         79084.10       0      125510.820000   \n",
       "\n",
       "   SalaryByProducts  meta_svm  meta_gb  \n",
       "0        101348.880         1        0  \n",
       "1        112542.580         0        0  \n",
       "2         37977.190         1        1  \n",
       "3         46913.315         0        0  \n",
       "4         79084.100         0        0  "
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metasvm = clf1.predict(Xs)\n",
    "metagb = clf2.predict(Xs)\n",
    "\n",
    "metasvm2 = clf1.predict(valXs)\n",
    "metagb2 = clf2.predict(valXs)\n",
    "train3 = train2.assign(meta_svm=metasvm, meta_gb=metagb)\n",
    "valX2 = valX.assign(meta_svm=metasvm2, meta_gb=metagb2)\n",
    "train3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>IsMale</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>BalanceByProducts</th>\n",
       "      <th>SalaryByProducts</th>\n",
       "      <th>meta_svm</th>\n",
       "      <th>meta_gb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>720</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>102882.40</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35633.15</td>\n",
       "      <td>51441.20</td>\n",
       "      <td>17816.575</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6956</th>\n",
       "      <td>571</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>180614.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>523.00</td>\n",
       "      <td>180614.04</td>\n",
       "      <td>523.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9479</th>\n",
       "      <td>781</td>\n",
       "      <td>Spain</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42117.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21058.950</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9126</th>\n",
       "      <td>753</td>\n",
       "      <td>Spain</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>79811.72</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>68260.27</td>\n",
       "      <td>39905.86</td>\n",
       "      <td>34130.135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4329</th>\n",
       "      <td>748</td>\n",
       "      <td>Spain</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>78194.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>39097.185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  IsMale  Age  Tenure    Balance  NumOfProducts  \\\n",
       "2049          720    France       0   45       1  102882.40              2   \n",
       "6956          571    France       1   49       4  180614.04              1   \n",
       "9479          781     Spain       1   35       1       0.00              2   \n",
       "9126          753     Spain       1   51       4   79811.72              2   \n",
       "4329          748     Spain       1   60       3       0.00              2   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  BalanceByProducts  \\\n",
       "2049          1               1         35633.15           51441.20   \n",
       "6956          0               0           523.00          180614.04   \n",
       "9479          0               0         42117.90               0.00   \n",
       "9126          0               1         68260.27           39905.86   \n",
       "4329          1               1         78194.37               0.00   \n",
       "\n",
       "      SalaryByProducts  meta_svm  meta_gb  \n",
       "2049         17816.575         1        0  \n",
       "6956           523.000         1        0  \n",
       "9479         21058.950         0        0  \n",
       "9126         34130.135         0        0  \n",
       "4329         39097.185         0        0  "
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valX2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now re split-scale-recombine our datasets, then train a fancy new model! :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempt3 = pandas.get_dummies(train3)\n",
    "tr3n, tr3c = re_order_unbind_2(tempt3)\n",
    "train4 = scale_rebind(tr3n, tr3c)\n",
    "\n",
    "tempvalx3 = pandas.get_dummies(valX2)\n",
    "v3n, v3c = re_order_unbind_2(tempvalx3)\n",
    "valX3 = scale_rebind(v3n, v3c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
