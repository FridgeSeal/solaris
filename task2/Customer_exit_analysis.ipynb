{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import seaborn as sb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.feature_extraction as fe\n",
    "import sklearn.preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, GridSearchCV\n",
    "import sklearn.neighbors as nhb\n",
    "import sklearn.ensemble as es\n",
    "import sklearn.tree as tree\n",
    "from sklearn import svm\n",
    "import sklearn.naive_bayes as nb\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.metrics import classification_report, fbeta_score, make_scorer, log_loss, accuracy_score, roc_auc_score, brier_score_loss\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "import sklearn.calibration as cl\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pandas.read_csv('data/account_histroy_data.csv')\n",
    "test = pandas.read_csv('data/existing_account.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(labels = ['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "train = train.replace({'Gender': {'Female': 0, 'Male': 1}})\n",
    "train = train.rename(columns={'Gender': 'IsMale'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd986576710>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matplotlib.style.use('ggplot')\n",
    "train['IsMale'].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial analysis\n",
    "\n",
    "* `RowNumber`, `CustomerID` and `Surname` can be dropped \n",
    "* `CreditScore` whilst numerical should be treated more like a ordinal variable. Nice and normal distribution. No missing values\n",
    "* `Age` is nicely behaved: no missing values, nice and finite, nice and normally distributed\n",
    "* `Tenure` is similarly nicely behaved: no missing values, finitely bounded and practically uniformally distributed. What does this variable represent? Age of account?\n",
    "* `Balance` is a bit more interesting: there's a large spike at ~<= 30k and then a normally distributed group centered at just over 100k. This suggests 2 separate populations. No na values\n",
    "* `NumOfProducts` is uninteresting: no missing values, all integers in [1,4]. All same order of magnitude\n",
    "* `HasCrCard` binary variable indicating credit card ownership. No missing values. Distribution of both classes is same order of magnitude, positive value (`1`) outweighs `0` value by about 4k occurences.\n",
    "* `IsActiveMember` binary variable. Practically class sizes. No missing values.\n",
    "* `EstimatedSalary` nicely behaved: uniform distribution with no missing values and all values in the same order of magnitude.\n",
    "* `Exited` Target variable. 1 indicates customer left, inbalanced classes with most cases in the \"stayed\" category.\n",
    "\n",
    "# Potential process\n",
    "\n",
    "* Given we don't have to worry about missing values, send the data straight to an `sklearn DictVectoriser` (as we want to track column names) followed by `OneHotEncoder` to handle binary variables that \n",
    "* This will automatically handle binarising our categorical variables.\n",
    "* Most variables were normally or uniformally distributed, so standard scaling should be sufficient, but test with robust scaling as well.\n",
    "* We've got enough data points that we can comfortable affort to slice off a portion of the dataset as a validation set. This can be done post scaling, pre test-train split. This will help prevent overfitting.\n",
    "* The class imbalance isn't too bad (they're both on the same order of magnitude), but it would be worth testing over/under/synthetic sampling approaches anyways.\n",
    "* We're treating this as a classification exercise, so let's run it across Naive Bayes, some forests of trees, gradient boosting, SVM's. As a baseline/sanity check let's run super basic logistic and single-tree models as well. ~~Bigger~~ Fancier isn't always better.\n",
    "* Model stacking and voting classifiers (soft and hard) are also worth investigating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>IsMale</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [CreditScore, Geography, IsMale, Age, Tenure, Balance, NumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary, Exited]\n",
       "Index: []"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['EstimatedSalary'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd9865a8748>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = train[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited']].corr()\n",
    "camp = sb.diverging_palette(220, 10, as_cmap=True)\n",
    "sb.heatmap(corr, cmap=camp, square=True, linewidths=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Matrix\n",
    "While it appears pretty uniform at first glance, there's some interesting stuff lurking here: whilst most of the variables exhibit near 0 correlation, there's some positive correlation between `age` and `exited` and some (relatively) strong negative correlation between `NumOfProducts` and `Balance`. There's also a weak negative correlation between `IsActiveMember` and `Exited`; possibly too weak to be useful, but worth keeping in mind.\n",
    "\n",
    "# Feature Engineering\n",
    "What features can we make that will add something meaningful and useful?\n",
    "* Balance / NumOfProducts?\n",
    "* EstimatedSalary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's slice off a validation set now so we can completely isolate it from the train and test data.\n",
    "validation = train[['CreditScore', 'Geography', 'IsMale', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited']].sample(frac=0.1)\n",
    "train2 = train[~train.index.isin(validation.index)]# Drop the validation values from the primary train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>IsMale</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  IsMale  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France       0   42       2       0.00              1   \n",
       "1          608     Spain       0   41       1   83807.86              1   \n",
       "2          502    France       0   42       8  159660.80              3   \n",
       "3          699    France       0   39       1       0.00              2   \n",
       "4          850     Spain       0   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_target(data):\n",
    "    cols = data.columns\n",
    "    target = data['Exited']\n",
    "    rem = data[cols.drop('Exited')]\n",
    "    return rem, target\n",
    "def re_order_unbind(data): \n",
    "    re_ordering = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary', 'IsMale', 'HasCrCard', 'IsActiveMember', 'Geography_France', 'Geography_Germany', 'Geography_Spain']\n",
    "    num_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "    cat_cols = ['IsMale', 'HasCrCard', 'IsActiveMember', 'Geography_France', 'Geography_Germany', 'Geography_Spain']\n",
    "    data = data[re_ordering]\n",
    "    numerical = data[num_cols]\n",
    "    categorical = data[cat_cols]\n",
    "    return numerical, categorical\n",
    "def scale_rebind(num, cat):\n",
    "    scalefn = pp.StandardScaler()\n",
    "    scaled = scalefn.fit_transform(num)\n",
    "    return np.concatenate([scaled, cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lots of algorithms expect (and perform better) when data is in the same scale. However, it doesn't much sense to scale categorical variables, so we re-order the dataset for ease of interpretation then separate it\n",
    "# into numerical and categorical sections, scale the numerical data and then rejoin everything back into the one dataset. Turning it into a function means we have a nice, single place to change our scaling type\n",
    "# later if we want to test other types.\n",
    "\n",
    "X,Y = sep_target(train2)\n",
    "tempX = pandas.get_dummies(X)  # Splits categorical/text columns containing n categories into n binary variables\n",
    "Xn, Xc = re_order_unbind(tempX)\n",
    "Xs = scale_rebind(Xn, Xc)\n",
    "\n",
    "valX, valY = sep_target(validation)\n",
    "temp_valX = pandas.get_dummies(valX)\n",
    "valXn, valXc = re_order_unbind(temp_valX)\n",
    "valXs = scale_rebind(valXn, valXc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thoughts on ML/fitting process\n",
    "\n",
    "We are trying to predict whether a user will leave/stop being a customer. We have a large choice of metrics with which to evaluate estimator performance. Measuring model confidence via probabilities would be ideal as it will let us generate the `log-loss` metric which means we can optimise for an estimator that is not \"confidently wrong\" which would result in lost clients. Outputting probabilities is also useful because it would give the sales/retention/etc team the ability to prioritise certain customers based on how likely they are to churn. `F1` or `Fbeta` score would probably be the next best metric to evaluate with. Weighting for `Fbeta` could go either way. On one hand we don't want to raise false-positives on clients that weren't going to churn because this wastes sales' effort (but has no negative effect on the customer), but weighting too heavily for precision could lead to potential churn-customers being lost in order for the model to preserve the accuracy of the ones it is confident in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'svm': svm.SVC(),\n",
    "    'svm_poly': svm.SVC(),\n",
    "    'knn': nhb.KNeighborsClassifier(),\n",
    "    'naive_bayes': nb.GaussianNB(),\n",
    "#     'decision_tree': tree.DecisionTreeClassifier(),\n",
    "    'random_forest': es.RandomForestClassifier(),\n",
    "    'adaBoost': es.AdaBoostClassifier(),\n",
    "    'Gradient_Boosting': es.GradientBoostingClassifier(),\n",
    "    'Logistic_Regression': lm.LogisticRegression()\n",
    "    #'Voting classifier'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'C': 0.5, 'class_weight': 'balanced', 'coef0': 0.4, 'degree': 3, 'gamma': 0.3, 'kernel': 'poly', 'probability': True, 'random_state': 74}\n",
    "svm_params = {'C': [1, 0.5, 0.1], 'kernel': ['linear', 'rbf',], 'gamma': ['auto', 0.3], \n",
    "             'probability': [True], 'class_weight': ['balanced', None], 'random_state': [74]}\n",
    "svm_poly_params = {'C': [0.5, 0.8, 0.25], 'kernel': ['poly'], 'degree': [2,3,5], 'gamma': ['auto', 0.1, 0.3], 'coef0': [0, 0.4, 0.6],\n",
    "                'probability': [True], 'class_weight': ['balanced', None], 'random_state': [74]},\n",
    "knn_params = {'n_neighbors': [3, 5, 9, 10, 15], 'weights': ['uniform', 'distance'], 'algorithm': ['kd_tree']}\n",
    "nb_params = None\n",
    "tree_params = None\n",
    "forest_params = {'n_estimators': [50, 80, 150, 200, 250], 'max_features': ['auto', None, 0.5,0.8], 'min_samples_split': [0.3, 0.5, 0.8],\n",
    "                'bootstrap': [True, False], 'n_jobs': [-1], 'random_state': [74], 'class_weight': ['balanced', None, 'balanced_subsample'], 'warm_start': [False]}\n",
    "ada_params = {'n_estimators': [30, 40, 50, 80, 100, 150], 'learning_rate': [0.1, 0.2, 0.3, 0.35, 0.25], 'random_state': [74]},\n",
    "gb_params = {'learning_rate': [0.1, 0.05], 'n_estimators': [100, 200, 300, 400, 500, 600], 'max_depth': [3, 6, 10], 'min_samples_split': [0.5, 0.3, 0.75],\n",
    "            'min_samples_leaf': [1,3, 0.5, 0.2], 'subsample': [0.5, 1], 'max_features': [None, 'auto'], 'random_state': [74]}\n",
    "logistic_params = {'C': [1, 0.75, 0.6, 0.4], 'class_weight': ['balanced', None], 'random_state': [74], 'max_iter': [300], 'warm_start': [True, False], 'n_jobs': [-1]}\n",
    "voting_params = None\n",
    "params = {'svm': svm_params,\n",
    "          'svm_poly': svm_poly_params,\n",
    "          'knn': knn_params,\n",
    "#           'decision TREE': tree_params,\n",
    "          'random_forest': forest_params,\n",
    "          'adaBoost': ada_params,\n",
    "          'Gradient_Boosting': gb_params,\n",
    "          'Logistic_Regression': logistic_params}\n",
    "#           'Voting classifier': voting_params}  # Leave this one out until we've got some good models to vote with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model: svm\n",
      "{'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.3, 'kernel': 'rbf', 'probability': True, 'random_state': 74}\n",
      "5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.76      0.83       767\n",
      "          1       0.45      0.74      0.56       203\n",
      "\n",
      "avg / total       0.82      0.76      0.78       970\n",
      "\n",
      "\n",
      "\n",
      "Testing model: svm_poly\n",
      "{'C': 0.25, 'class_weight': 'balanced', 'coef0': 0, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly', 'probability': True, 'random_state': 74}\n",
      "5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.75      0.82       767\n",
      "          1       0.43      0.72      0.54       203\n",
      "\n",
      "avg / total       0.81      0.75      0.76       970\n",
      "\n",
      "\n",
      "\n",
      "Testing model: knn\n",
      "{'algorithm': 'kd_tree', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.91      0.88       767\n",
      "          1       0.56      0.43      0.49       203\n",
      "\n",
      "avg / total       0.80      0.81      0.80       970\n",
      "\n",
      "\n",
      "\n",
      "Testing model: random_forest\n",
      "{'bootstrap': True, 'class_weight': 'balanced', 'max_features': 'auto', 'min_samples_split': 0.8, 'n_estimators': 50, 'n_jobs': -1, 'random_state': 74, 'warm_start': False}\n",
      "5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       767\n",
      "          1       0.21      1.00      0.35       203\n",
      "\n",
      "avg / total       0.04      0.21      0.07       970\n",
      "\n",
      "\n",
      "\n",
      "Testing model: adaBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.35, 'n_estimators': 150, 'random_state': 74}\n",
      "5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.95      0.90       767\n",
      "          1       0.69      0.43      0.53       203\n",
      "\n",
      "avg / total       0.83      0.84      0.83       970\n",
      "\n",
      "\n",
      "\n",
      "Testing model: Gradient_Boosting\n",
      "{'learning_rate': 0.1, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 0.3, 'n_estimators': 600, 'random_state': 74, 'subsample': 1}\n",
      "5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.95      0.91       767\n",
      "          1       0.69      0.46      0.55       203\n",
      "\n",
      "avg / total       0.83      0.84      0.83       970\n",
      "\n",
      "\n",
      "\n",
      "Testing model: Logistic_Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'class_weight': 'balanced', 'max_iter': 300, 'n_jobs': -1, 'random_state': 74, 'warm_start': True}\n",
      "5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.72      0.80       767\n",
      "          1       0.40      0.69      0.51       203\n",
      "\n",
      "avg / total       0.79      0.72      0.74       970\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomwatson/.local/share/virtualenvs/task2-rEKsIwwa/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    }
   ],
   "source": [
    "# We're going to build the models to optimise for recall first, then model stack with the best one(s) and then build a 2nd generation of models optimising for precision/log-loss.\n",
    "for model, parameters in params.items():\n",
    "    print()\n",
    "    print()\n",
    "    print(f'Testing model: {model}')\n",
    "    clf = GridSearchCV(estimator=models[model],\n",
    "                       param_grid=parameters,\n",
    "                       cv=5,\n",
    "                       scoring='recall',\n",
    "                       n_jobs=-1,\n",
    "                      refit='recall')\n",
    "    clf.fit(Xs, Y)\n",
    "    print(clf.best_params_)\n",
    "    print(clf.n_splits_)\n",
    "    est = clf.best_estimator_\n",
    "    y_pred = est.predict(valXs)\n",
    "    print(classification_report(valY, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Results:\n",
    "* Plain SVM's performed average at best, with middling precision but good recall: `0.49` and `0.72` respectively and `0.58` for the f1 score.\n",
    "* Polynomial SVM's performed better with improvements to precision, recall and f1 score: `0.5`, `0.74` and `0.6` respectively.\n",
    "Optimising precision and recall is a tradeoff, but for our case, because we don't want to risk losing customers, we want to bias slightly towards recall.\n",
    "* Plain random forests and adaBoost haven't been too suitable for our use-case: they both perform exceedingly well with regards to precision - scoring `0.81` and `0.94` respectively but very poorly when it comes to recall with both models scoring `<= 0.1` for the target value (left). This isn't ideal as it means that whilst their predictions for customers leaving are accurate (they're generating very few false positives), they're essentially underestimating/underpredicting the number of customers who would leave. That is, in production, they would not flag a large percentage of customers who are about to leave.\n",
    "* There is an upside, we can still make use of the high precision of these models by using model-stacking. This is where we'll use a model (adaBoost and svm_poly in this case) to generate predictions for all samples in the greater training and validation set (`Xs` and `valXs`) and these add a column in each dataset. We'll then train another model using this new dataset, this allows us to guide/help successive models with extra information.\n",
    "\n",
    "# Best models so far:\n",
    "Polynomial SVM  \n",
    "```\n",
    "{'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.3, 'kernel': 'rbf', 'probability': True, 'random_state': 74}\n",
    "5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          0       0.92      0.76      0.83       767\n",
    "          1       0.45      0.74      0.56       203\n",
    "\n",
    "avg / total       0.82      0.76      0.78       970```  \n",
    "Gradient Boosting Trees  \n",
    "```\n",
    "{'learning_rate': 0.1, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 0.3, 'n_estimators': 600, 'random_state': 74, 'subsample': 1}\n",
    "5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          0       0.87      0.95      0.91       767\n",
    "          1       0.69      0.46      0.55       203\n",
    "\n",
    "avg / total       0.83      0.84      0.83       970```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "#Let's roll with the polynomial SVM for now, as that seems to have the best balance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Improvements\n",
    "\n",
    "Once we have a couple of models that we're reasonably happy with, we can run probability calibration on them. This will ideally have the effect of minimising the effects of over-confidence/underconfidence. As a result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plain SVM:  \n",
    "`{'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.3, 'kernel': 'rbf', 'probability': True, 'random_state': 74}`  \n",
    "and Gradient Boosted Trees:  \n",
    "`{'learning_rate': 0.1, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 0.3, 'n_estimators': 600, 'random_state': 74, 'subsample': 1}`  \n",
    "Check log-loss and ROC-AUC stats for these, then see if their probability-calibrated versions yield any improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No calibration: 0.11048031215674682\n",
      "Sigmoid calibration: 0.11068407528511306\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C=0.8, class_weight='balanced', coef0=0.6, degree=3, gamma='auto', kernel='poly', probability=True, random_state=74)\n",
    "clf2 = clf.fit(Xs, Y)\n",
    "uncalibrated = clf2.predict_proba(valXs)[:,1]\n",
    "clb = cl.CalibratedClassifierCV(base_estimator=svm.SVC(C=0.8, class_weight='balanced', coef0=0.6, degree=3, gamma='auto', kernel='poly', probability=True).fit(Xs, Y), cv='prefit', method='sigmoid')\n",
    "clb = clb.fit(Xs, Y)\n",
    "calibrated = clb.predict_proba(valXs)[:,1]\n",
    "print(f'No calibration: {brier_score_loss(valY, uncalibrated)}')\n",
    "print(f'Sigmoid calibration: {brier_score_loss(valY, calibrated)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Interestingly, probability calibration seems ever-so-slightly worsen the Brier score, but the change is very small (order of 1x10^-4) and Brier score is a `[0, 1]` bounded metric, so our score of `~0.110`  \n",
    "is already quite good.  \n",
    "Running the original and calibrated models against the validation set to compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.80      0.86       767\n",
      "          1       0.50      0.75      0.60       203\n",
      "\n",
      "avg / total       0.83      0.79      0.80       970\n",
      "\n",
      "0.790721649484536\n",
      "7.228343450490987\n",
      "0.7752968831285605\n"
     ]
    }
   ],
   "source": [
    "ypred = clf2.predict(valXs)\n",
    "print(classification_report(valY, ypred))\n",
    "print(accuracy_score(valY, ypred))\n",
    "print(log_loss(valY, ypred))  # Our model is a ~~little bit~~ very overconfident\n",
    "print(roc_auc_score(valY, ypred))  # ROC AUC score looks good though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       767\n",
      "          1       0.74      0.49      0.59       203\n",
      "\n",
      "avg / total       0.85      0.86      0.85       970\n",
      "\n",
      "0.8577319587628865\n",
      "4.913792915884259\n",
      "0.7234892518352484\n"
     ]
    }
   ],
   "source": [
    "ypred = clb.predict(valXs)\n",
    "print(classification_report(valY, ypred))\n",
    "print(accuracy_score(valY, ypred))\n",
    "print(log_loss(valY, ypred))  # Still very over-confident, but an improvement\n",
    "print(roc_auc_score(valY, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run across the validation set we can see good improvements in accuracy and log-loss. ROC AUC score has decreased a small, almost negligible amount.\n",
    "Seems the calibration has pushed the model towards increased precision at the cost of some recall.\n",
    "Given we want to bias towards increased recall, let's use the uncalibrated model to model stack with, and then train a model that focuses heavily on precision and log-loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stack = clf2.predict(Xs)\n",
    "val_stack = clf2.predict(valXs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8729, 12)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.32612953, -1.09562919,  0.28969876, -1.04365974, -1.21826603,\n",
       "       -0.91386531,  0.64329791,  0.97253868,  0.01798931,  0.99965638,\n",
       "       -0.57783531, -0.57660066])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
